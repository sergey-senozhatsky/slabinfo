TL;DL
===============================================================================

A quick tutorial

# start collecting samples, record file name is NOMERGE, note sudo
sudo ./slabinfo-stats.sh -r NOMERGE

#^C or reboot

#pre-process records file for gnuplot
./slabinfo-stats.sh -p FILE1[,FILE2,...] -b gnuplot
File gnuplot_slabs-by-loss-FILE1
File gnuplot_slabs-by-size-FILE1
File gnuplot_totals-FILE1
...


#generate a plot from 'slabinfo totals'
./gnuplotter.sh -m totals -f gnuplot_totals-NOMERGE

To collect another samples (e.g. record file MERGE) and to visually compare
two record files (e.g. MERGE and NOMERGE), do

sudo ./slabinfo-stats.sh -r MERGE
./slabinfo-stats.sh -p MERGE -b gnuplot
^C
./gnuplotter.sh -m totals -f gnuplot_totals-MERGE,gnuplot_totals-NOMERGE

etc.

'gnuplotter.sh -m totals -f'   accepts any number of RECORD files.


USAGE
===============================================================================

First, we need to collect samples that later will be pre-process and used by a
plotting program. Different scripts are used for those tasks, because the basic
design is not to stick to a one and only plotting program, but instead provide
an ability to implement support for any plotting back-end (gnuplot, PLplot,
etc.) that fits your own needs. Apart from that, this split lets you to collect
samples on a target machine and to generate plots on a host machine (your target
may be missing gnuplot, etc.).

slabinfo-stats.sh, thus, provides two functions:
-- it's a wrapper around slabinfo tool, that is used to collect the data
-- it's a pre-processor that is used to grep | awk | etc. collected samples in
a plotting back-end specific way


NOTE:
slabinfo tool must be patched in order to provide extended stats and info.
Find the kernel patches in kernel_patches/ directory.


To record samples, execute
slabinfo-stats.sh -r FILE

To pre-process recorded sample file(-s) execute
slabinfo-stats.sh -p FILE1,[,FILE2,...] [-b gnuplot,etc.]

-b option (as of now) is optional; by default script will try to pre-process
the samples for gnuplot.


Other options:
-n %d 	- tell slabinfo to print only %d first slabs in stats tables
-s %d	- sleep timeout between samples


The rest is handled by plotting scripts.


GENERATING A PLOT
===============================================================================

As of now, only gnuplot supported by gnuplotter.sh script:

 -m  slabs
   Generate plot based on "Slabs sorted by FOO" slabinfo output (both 'sort by
   loss' and 'sort by size' files)

   This script handles files with gnuplot_slabs-by-loss-* or
   gnuplot_slabs-by-size-* in their names.


 -m  totals
   Generate plot based on Total "Memory usage and Loss" slabinfo output

   This script handles files with gnuplot_totals-* in their names.

 -r %d,%d
 This option specifies a range of samples to be plotted. It basically scales
 the graph for more detailed investigation and at the same  helps when the
 number of samples is too high to be plotted nicely.
 See
	examples/gnuplot_totals-nomerge-vs-gnuplot_totals-nomerge2.png
	examples/gnuplot_totals-nomerge-vs-gnuplot_totals-nomerge2-r70,350.png
 or
	examples/gnuplot_slabs-by-loss-nomerge-r300,600.png
	examples/gnuplot_slabs-by-loss-nomerge-r450,550.png


 -s %d,%d
 This option lets to redefine generated image width and heigh (pixels)


 -f FILE1 [,FILE2,...]    (mandatory)
 Specifies the file(-s) to process.


SAMPLES
===============================================================================

Samples are just a set of numbers and names, one can grep|awk|etc.
and pickup up any of them depending on the needs.

Samples have:
-- a seq number "Sample #X" so it's easier to grep the samples file
-- slabinto -T reporting part
-- slabinfo `Slabs sorted by size' and `Slabs sorted by loss' tables

Each record file starts with the following lines:
 uname -r
 cat /proc/cmdline
 slabs_pertable:$lines


EXAMPLE:

Sample #1
Slabcache Totals
----------------
Slabcaches : 140      Aliases  :   0->0   Active: 109
Memory used: 244441088   # Loss   : 11651888   MRatio:     5%
# Objects  : 408174   # PartObj:  11658   ORatio:     2%

Per Cache    Average         Min         Max       Total
---------------------------------------------------------
#Objects        3744          11      109154      408174
#Slabs           140           1        4854       15267
#PartSlab          4           0         148         528
%PartSlab         3%          0%         57%          3%
PartObjs           2           0        6137       11658
% PartObj         1%          0%         41%          2%
Memory       2242578        4096   159055872   244441088
Used         2135680        3360   151677792   232789200
Loss          106898           0     7378080    11651888

Per Object   Average         Min         Max
---------------------------------------------
Memory           573           8        8192
User             570           8        8192
Loss               2           0          64

Slabs sorted by size
----------------------
Name                   Objects Objsize                Space Slabs/Part/Cpu  O/S O %Fr %Ef Flg
ext4_inode_cache         87372    1736            159055872      4833/0/21   18 3   0  95 a
dentry                  109154     288             31997952     3880/36/26   28 1   0  98 a
inode_cache              12366     864             11255808        680/0/7   18 2   0  94 a
buffer_head              56628     104              5947392      1438/0/14   39 0   0  99 a
radix_tree_node           7056     576              4128768        245/0/7   28 2   0  98 a

Slabs sorted by loss
----------------------
ext4_inode_cache         87372    1736              7378080      4833/0/21   18 3   0  95 a
kmalloc-2048              1591    2048               575488      102/37/15   16 3  31  84 
inode_cache              12366     864               571584        680/0/7   18 2   0  94 a
dentry                  109154     288               561600     3880/36/26   28 1   0  98 a
shmem_inode_cache         2055    1040               320400       47/16/28   31 3  21  86 



Sergey Senozhatsky, 2015
